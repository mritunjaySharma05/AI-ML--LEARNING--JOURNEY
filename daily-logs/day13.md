# Day 13 â€“ Decision Tree Classifier

**Date:** [May 28, 2025]

---

## ğŸ“˜ What I Learned Today

### ğŸ”¹ Decision Tree Classifier
A supervised learning algorithm that mimics human decision-making.

- Represents decisions as a tree structure
- Nodes ask questions (e.g., Marks > 60?)
- Leaves give predictions ("Pass" or "Fail")

---

## ğŸ§  Key Concepts

| Concept       | Meaning                                       |
|---------------|-----------------------------------------------|
| Root Node     | First decision based on a feature             |
| Internal Node | Follow-up feature-based conditions            |
| Leaves        | Final class predictions                       |
| Entropy/Gini  | Metrics used to choose best split             |

---

## ğŸ› ï¸ Steps I Performed

- Loaded CSV with "Marks" and "Result"
- Converted labels ("Pass"/"Fail") into 1s and 0s
- Split the dataset with `train_test_split()`
- Trained `DecisionTreeClassifier()`
- Evaluated predictions and accuracy
- Visualized the full tree with `plot_tree()`

---

## ğŸ“Š Output

Achieved high accuracy due to clean, simple data.

**Sample Rule:**  
- If Marks â‰¤ 58.5 â†’ Predict "Fail"  
- Else â†’ Predict "Pass"

---

## ğŸ““ Notebook

Notebook with code & examples: [`day13.ipynb`](day13.ipynb)
